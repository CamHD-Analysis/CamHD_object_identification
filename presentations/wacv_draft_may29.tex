\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{wacv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
%\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%\wacvfinalcopy % *** Uncomment this line for the final submission

\def\wacvPaperID{****} % *** Enter the wacv Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifwacvfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Instance Segmentation of Deep Sea Scaleworms at Hydrothermal Vent}

% Authors at the same institution
%\author{First Author \hspace{2cm} Second Author \\
%Institution1\\
%{\tt\small firstauthor@i1.org}
%}
% Authors at different institutions
\author{First Author \\
Institution1\\
{\tt\small firstauthor@i1.org}
\and
Second Author \\
Institution2\\
{\tt\small secondauthor@i2.org}
}

\maketitle
\ifwacvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
   #TODO: Written at the end.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

- OOI motivation, NSF goals etc. Cabled array setup in ocean. Observe and Explore deep sea (depth) and hydrothermal vent. probably an image to show where it is located. Mushroom, the hydrothermal vent being observed.

- CamHD instrument. Videos spanning the Mushroom, different zoom levels, taken continuously over years. Capturing colorful diverse benthic biology site. Extreme environment - temp (different between head (freezing) and toe (burning)), pressure, toxins, no sunlight. But due to Chemosynthesis: life is thriving, thanks to bacteria. Many organisms live in this area - examples like tubeworms, arachnids, starfishes, crabs, scaleworms and many more unidentified species. Underwater robots helped in discovering these species, and such short-term video surveillances were mostly manually analyzed to study these species. We need long-term population studies can unravel many mysteries of this world and help us in understanding how to conserve such environments. But it was hard to study these areas due to their challenging locations. But, with video data from CamHD (which we have open-sourced for research purposes), we have means to perform long-term studies this region, but manually not possible because of the volume of data. Therefore, automatic analysis is required.

- In this paper, we consider one such species found in these videos - Scaleworms, which have been biologically studied and found to have interesting properties as found in the Nature article \href{Nature article}{https://www.nature.com/articles/srep46205}, and from \href{another study}{https://pdfs.semanticscholar.org/49ae/4831505b891f771d468bcd9f5df8ca3caf92.pdf}. We propose an application of an instance segmentation method to identify, count and estimate the size of each scaleworm from a video frame. We believe that such a system will help in opening up the possibilities for large-scale population studies on such species, which currently is not available as fr as we know.

- Challenge: We discuss various challenges in analysing this data. Video, non-constant static regions, schliren distortions, lighting failures, and the nature of our target object - scale worms. The scaleworms vary in size, color shades and often look camafloughed due to the dense surrounding having dynamic colors. Also, they often stay on plant-like tube worms which keep oscillating at times due to the force of the fumes coming out of the vent. And the shortage of labeled data.

<a frame image where scaleworms are marked in green arrow marks and confusing objects are marked with red arrow marks and labeled to give reader an idea of the image we are dealing with>

Paper organization: lit-survey, problem statement, methodology, results with discussions and limitations, conclusion and future work.

%-------------------------------------------------------------------------
\section{Literature Review}

- Previous application reviews
Previous research containing the underwater object detection and segmentation. What methods were used. Unsupervised image processing methods, like histogram equalization or background separation would not work in our case. How our challenges are different.

    - https://ieeexplore.ieee.org/document/8698738

    - https://www.nature.com/articles/s41598-018-32089-8
 
    - http://ceur-ws.org/Vol-1866/paper_166.pdf
 
    - https://www.researchgate.net/publication/266632361_Underwater_Real-Time_Fish_Recognition_by_Image_Processing
 
    - https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1739&context=amcis2006
 
    - https://ieeexplore.ieee.org/abstract/document/1315079

- Related methods review
    - U-Net, biomedical image scenario seems closer to our scenario, and exploring the popular U-Net model for segmentation. Its pros and cons.

    - MaskRCNN: pros and cons.

    We aim to derive inspiration from these methods and propose a simple framework, which is easy to interpret and hence debug, and which scales well with more train data and easy to maintain.
    
\textcolor{red}{Example: The segmentation of objects and animals in imagery is well studied (CITE survey papers, state of the art works, etc..) However, these approaches have not been explored for subsea classification. Researchers have attempted subsea classification using standard image processing methods like (CITE, CITE,...,CITE). Due to the difficult nature of the CamHD data, none of these approaches will work for our imagery. However, a recent bio-medical image segmentation algorithm \textit{U-Net} has been shown to work well for challenging segmentation problems. U-Net has several limitations, such as BLAH BLAH BLAH, which is why the use of a post-processing CNN is necessitated. Similar methods have been shown to be successful in (Faster-RCNN CITE CITE...).}.

%------------------------------------------------------------------------
\section{Proposed Methodology}

In this section, we describe the data collection and proprocessing details, followed by the objectives of the and evaluation metrics. Hence, we provide detailed explanation of our multi-step analysis pipeline for localizing and segmenting the scaleworms.

%-------------------------------------------------------------------------
\subsection{Data Collection and Preprocessing}
We receive 15-min CamHD videos having a 1920x1080 resolution, 8 times a day at 3 hour intervals. We have collected TODO number of videos since TODO date. For the purpose of this study, all these videos are unlabeled. We can tap into the potential of these videos only if we can autonomously quantify the scaleworm population data. We consider videos from July through October (4 months) of 2018, to build this proof-of-concept solution to identify scaleworms on this data subset.

A 15-min CamHD video follows a pre-configured routine during which it spans across different regions of the hydrothermal vent, zooming in at certain locations. Due to the challenges of the setup and the dynamic sub-sea schlieren caused by the extreme heat from the hydrothermal vent, we cannot always observe a particular scene at a specific timestamp. The optical flow solution by TODO (Aaron) \etal \cite{aaron_prevwork}, determines the static-regions of the CamHD video. We manually assigned scene-tags to label the static-regions for a subset of data which belong to a particular scene in the video, and used this labeled data to train a Convolutional Neural Network (CNN) to classify a given static-region, so that it can autonomously assign a scene-tag to it. This system is reliably maintained to provide validated scene-tags to each static-region of the video.

Particularly from 3 specific scenes, we could observe considerable amount of scaleworms. Therefore, we design the application to quantify the scaleworms and their structures from these 3 scenes from each CamHD video. In this initial attempt, we decided to work at a frame-level. Hence we sampled several (TODO number) frames (images) corresponding to the 3 selected scenes, from the each video of our subset (July to October 2018).

We considered TODO number of images for manually creating segmentation mask, to create a labaled training set of images. LabelMe tool \cite{labelme} was used to create manual segmentation masks for TODO number of images. It is very difficult to spot each scaleworm in an image due to the vibrant background where scaleworms seem to be camafoughed). For practicaly reasons, a sparse labeling approach was followed for the train set images, which means that only a few scaleworms were labeled in each image. Over several images in the train set (TODO number of images did not contain scaleworms or was missed while labeling), we have collected labeled scaleworms under different scenarios including some in difficult and confusing labels. This train data was processed in two batches. We refer to the labeled train images from July and August as Set 1, and those from September and October as Set 2.

We held-out a small subset of frames as a separate test-set for evaluation purposes. This test-set consisted of 45 images (equal representation from each of the 3 scenes selected) which were densely labeled, which means that every visible scaleworm in each image was labeled. Note that dense labeling needs to be conducted with extreme focus to identify almost all scaleworms in an image (though some are confusing even for human eye), and hence is a very expensive process and hence it was not conducted on a larger set. Therefore, on the larger train data, only sparse labeling was practically possible.

%-------------------------------------------------------------------------
% TODO: Should we merge problem statement and evaluation into a section subsection?
\subsection{Problem Statement}
We aim localize and determine the size and shape of each scaleworm present in a given CamHD video frame (image). For each scaleworm present in the a CamHD image, the primary goal of the algorithm is to determine a binary segmentation mask such that the pixels corresponding to this scaleworm are ones and the rest are zeros, with a confidence score ([0, 1]). This would be instrumental to downstream tasks where the location of each scaleworm can be determined by the pixel coordinate corresponding to the centroid of the detected segmentation mask, and several morphological properties like area, length and width can also be inferred from the segmentation mask. Therefore, we can consider our problem in a standard setting of instance segmentation problem.

\subsubsection{Evaluation Method}
Scaleworms are generally observed in the neighbourhood of tubeworms. We observed that tubeworms and other background objects often occlude a portion of several scaleworms. Moreover, when the scaleworms are close to the tip of a tubeworm, it is very hard to manually distinguish the boundary of the scaleworm. Therefore, it is reasonable to to discount such inaccuracies in our application. Therefore, we choose a low Intersection over Union (IoU) threshold of 50\% (AP@[.5:.95]).

Standard instance segmentation dataset challenges like the Microsoft COCO \cite{cocodata}, use mean of Average Precision (AP) \cite{averageprecision} for IoU from 0.5 to 0.95 with a step size of 0.05, as an evaluation metric. Since we use 50\% IoU threshold in our application, for each scaleworm determined by the algorithm, we consider it as a valid scaleworm detection if the IoU of the predicted segmentation mask and the ground-truth segmentation mask is at least 50\%. Therefore, we consider Average Precision at 50\% IoU (AP@0.5\%) as our primary evaluation metric, instead of AP@[.5:.95].

%-------------------------------------------------------------------------
\subsection{Joint UNet-CNN Instance Segmentation Model.}

- challenge is less labeled data.

- small patches: less tensor sizes, easy to fit on a local GPU. less context, less confusion.

<image to show center crop and stitch>

<flowchart>

- Flowchart and explanation of each part. Reasoning for each decision (like batchnorm).

- Batch norm efficacy. val_mean_iou vs number of epochs, for with batchnorm vs without bathcnorm. (should this be in results section? this kind of helped in making the decision for the methodology, so this can be in methodology also, right?)

- Easy to debug and fix the model and work with limited labeled data which is essential when such data cant be crowdsourced for labeling.

- Sparse labeling is important because its hard to tag each and every scaleworm.

(include precise details, in training time and in inference time.)

%-------------------------------------------------------------------------
\section{Results and Discussion}

<Unet level training masks, and predicted mask>.

<flow of images in the pipeline to get the final output.> show the segmentations, but with overlay, its not really visible, so remove the overlay in the last image.

- test set details. how it was created.
- train data details, set 1 (2-months), set 2 (adding 2 more months data), set 3 (adding some selective negative patches).

- <table> with both unet+cnn trained on set1, set2, and set3. adding data helps in increasing the average precision. Therefore, we can spend more on getting the data to get better model.

- But this concerns maintainability, since we have to train two different models. Understand the imnprovement in average precision by just CNN or Just UNet. 

- <table> Keep v0.4 UNet constant, and keep adding data and training CNN. We observe a great increment. So CNN model contribues a lot.

- <table> What if we consider UNet trained on very less data, i.e., set 1. Still CNN keeps increasing the accuracy, but after some point it tends to not lead to high increase in accuracy. At that time, we might want to update UNet model.

- <table> show that keeping CNN model constant, improvement in UNet did not improve in any accuracy. This is mainly the case, because our final score mainly depends on CNN. (So this table might not be very useful)

-<training time on dataset of x size with batchsize, and inference time on an image>

\subsection{Advantages}
<Image showing where it is still not working>
- Can be overcome by iteratively identifying and all new negative patches. And thats how we can debug and control the model.

- Sparse labeling will suffice.

- Worked on relatively less data compared to the requirement of other Models which were not feasible with such low amount of data. (Hard to claim this. So we can try to put a reference showing that Other models need a lot of data.)

- Training and Testing since done on small patches, it can fit in personal computer GPU's like GTX 970. And relativels runs fast because of less parameters.

\subsection{Disadvantages}
- The score doesn't quantify the errors from UNet. Since CNN is the main contribution for getting the improvement, it is ok. But if we wanted Average recall, then we would need to propagate errors from UNet as well.

- We had a relatively small test set. Results from larger test sets could be useful. But hard to get more dense labeling for testing purpose.

%-------------------------------------------------------------------------
\section{Conclusion and Future Work}

This provides a decent result with a fairly simple model to start getting structures metadata info like count scaleworms, and the size of each scaleworm, in each of the scenes for a video. it is easy to debug and understand what kind of data needs to be added to improve it, and therefore by adding more data it has proven to improve, and especially by adding specific datam, it would improve in a larger magnitude. If run on all the data, we get a temporal distribution of scaleworm population, which could be very useful dataset to perform population study espectially by comparing the with the temperature at the hydrothermal vent to understand their behavior.

Future work may consider trying other more complex models on the data. MaskRCNN, PaNet could be tried. If segmentation is not required not, SSD, FasterRCNN can be tried on this data. The temporal information in the video, can also be exploited to identify the scaleworms with higher precision, as other objects would occilate but scaleworm wouldn't be oscillating in a short video-segment.

This prototype could help in adopting such techniques to such many other different organisms, some of which pose more challenges, and could help benthic biologists explore more of this hidden world of rich and diverse ecosystem near hydrothermal vents.

%-------------------------------------------------------------------------

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}


\end{document}
